#!/usr/bin/env python3
"""
LOOKS - Vast.ai GPU Worker
Corre EN la instancia Vast alquilada
Consume jobs de Supabase y ejecuta ComfyUI
"""

import os
import sys
import time
import json
import requests
from datetime import datetime
from supabase import create_client, Client
import base64
from pathlib import Path

# ============================================
# CONFIGURACIÃ“N
# ============================================

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
WORKER_ID = os.getenv("WORKER_ID", f"vast-worker-{int(time.time())}")
COMFY_URL = "http://127.0.0.1:8188"

WORKER_CONFIG = {
    'POLL_INTERVAL_SECONDS': 5,      # Polling cada 5s
    'MAX_BATCH_SIZE': 12,            # MÃ¡ximo 12 jobs simultÃ¡neos
    'MIN_BATCH_SIZE': 1,             # MÃ­nimo 1 (FCFS)
    'JOB_TIMEOUT_SECONDS': 300,      # Timeout 5 minutos
    'HEARTBEAT_INTERVAL_SECONDS': 30, # Heartbeat cada 30s
}

print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  LOOKS - Vast.ai GPU Worker                   â•‘
â•‘  Worker ID: {WORKER_ID:31s} â•‘
â•‘  ComfyUI: {COMFY_URL:34s} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

# Verificar variables de entorno
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ ERROR: SUPABASE_URL o SUPABASE_KEY no configurados")
    sys.exit(1)

# Cliente Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ============================================
# FUNCIONES AUXILIARES
# ============================================

def check_comfy_ready():
    """Verificar que ComfyUI estÃ© listo"""
    try:
        resp = requests.get(f"{COMFY_URL}/system_stats", timeout=5)
        return resp.status_code == 200
    except:
        return False

def download_image(url, local_path):
    """Descargar imagen de URL a filesystem local"""
    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
        
        Path(local_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(local_path, 'wb') as f:
            f.write(resp.content)
        
        return local_path
    except Exception as e:
        print(f"âŒ Error descargando {url}: {e}")
        raise

def build_tryon_prompt(products_metadata):
    """Construir prompt similar a buildTryOnPrompt de Node.js"""
    
    image_descriptions = []
    instructions = []
    
    # Detectar categorÃ­as
    has_top = any(p.get('category') == 'top' for p in products_metadata)
    has_outerwear = any(p.get('category') == 'outerwear' for p in products_metadata)
    has_bottom = any(p.get('category') == 'bottom' for p in products_metadata)
    
    for idx, product in enumerate(products_metadata):
        img_num = idx + 2  # Avatar es @image 1
        name = product.get('name', 'item')
        category = product.get('category', 'top')
        
        image_descriptions.append(f"@image {img_num} is {name}")
        
        if category == 'bottom':
            instructions.append(f"Replace the blue jeans with {name} from @image {img_num}")
        elif category == 'top':
            instructions.append(f"Replace the white t-shirt with {name} from @image {img_num} (worn directly on skin, base layer)")
        elif category == 'outerwear':
            if has_top:
                instructions.append(f"Add {name} from @image {img_num} as outer jacket layer (worn OVER the shirt/blouse, clearly visible as outermost layer)")
            else:
                instructions.append(f"Add {name} from @image {img_num} as jacket (worn over the white t-shirt)")
        elif category == 'dress':
            instructions.append(f"Replace ALL clothing with {name} from @image {img_num} (full-body dress)")
        elif category == 'accessories':
            instructions.append(f"Add {name} from @image {img_num}")
        elif category == 'footwear':
            instructions.append(f"Replace footwear with {name} from @image {img_num}")
        elif category == 'head':
            instructions.append(f"Add {name} from @image {img_num} on head/face")
        else:
            instructions.append(f"Add {name} from @image {img_num}")
    
    prompt = f"""@image 1 is the base avatar (person in white t-shirt and blue jeans).
{chr(10).join(image_descriptions)}

Edit @image 1 by applying these changes:
{chr(10).join(instructions)}

CRITICAL REQUIREMENTS:
- Preserve EXACT face, skin tone, and body from @image 1
- Maintain SAME soft studio lighting as @image 1 (no harsh shadows)
- Background: solid #FFFFFF pure white (RGB 255,255,255) - same as @image 1
- Keep SAME color temperature and exposure as @image 1
- Only change the clothing/accessories as specified
- Do NOT alter face, hair, skin color, or body proportions
- Do NOT add shadows on the background

Quality: 4K, consistent lighting, photorealistic, seamless white background."""
    
    return prompt

def execute_comfy_workflow(job):
    """
    Ejecutar workflow de ComfyUI para try-on
    TODO: Implementar llamada real a ComfyUI API
    Por ahora, retorna mock
    """
    
    job_id = job['id']
    
    print(f"ğŸ¬ [Job {job_id}] Ejecutando workflow ComfyUI...")
    
    # 1. Descargar imÃ¡genes
    avatar_url = job['input_data']['avatar_url']
    garments = job['input_data'].get('garment_images', [])
    
    avatar_path = f"/tmp/job_{job_id}_avatar.jpg"
    download_image(avatar_url, avatar_path)
    
    garment_paths = []
    for idx, garment in enumerate(garments[:3]):  # MÃ¡ximo 3 prendas
        path = f"/tmp/job_{job_id}_garment_{idx}.jpg"
        download_image(garment['url'], path)
        garment_paths.append(path)
    
    # 2. Construir prompt
    products_metadata = job['input_data'].get('products_metadata', [])
    prompt = build_tryon_prompt(products_metadata[:3])
    
    print(f"ğŸ“ [Job {job_id}] Prompt generado ({len(prompt)} chars)")
    
    # 3. TODO: Ejecutar ComfyUI workflow
    # Por ahora, mock - en producciÃ³n llamar a ComfyUI API
    # POST http://127.0.0.1:8188/prompt con workflow JSON
    
    """
    workflow = {
        "1": {
            "inputs": {"image": avatar_path},
            "class_type": "LoadImage",
        },
        # ... mÃ¡s nodos del workflow
    }
    
    resp = requests.post(f"{COMFY_URL}/prompt", json={"prompt": workflow})
    prompt_id = resp.json()["prompt_id"]
    
    # Polling hasta completado
    while True:
        history = requests.get(f"{COMFY_URL}/history/{prompt_id}").json()
        if prompt_id in history:
            # Extraer imagen final
            outputs = history[prompt_id]["outputs"]
            # ... procesar resultado
            break
        time.sleep(2)
    """
    
    # Mock: Simular que tarda 20 segundos
    print(f"â³ [Job {job_id}] Simulando procesamiento (20s)...")
    time.sleep(20)
    
    # Por ahora retornamos el avatar original (mock)
    result_path = avatar_path
    
    print(f"âœ… [Job {job_id}] Workflow completado")
    
    return result_path

def upload_result_to_supabase(job_id, user_id, result_path):
    """Subir resultado a Supabase Storage"""
    
    try:
        with open(result_path, 'rb') as f:
            file_data = f.read()
        
        file_name = f"tryon_{user_id}_{job_id}_{int(time.time())}.jpg"
        storage_path = f"{user_id}/tryons/{file_name}"
        
        print(f"ğŸ“¤ [Job {job_id}] Subiendo a Storage ({len(file_data)/1024:.1f} KB)...")
        
        # Upload a Supabase Storage
        supabase.storage.from_("avatars").upload(
            storage_path,
            file_data,
            file_options={"content-type": "image/jpeg", "upsert": "false"}
        )
        
        # Obtener URL pÃºblica
        public_url_response = supabase.storage.from_("avatars").get_public_url(storage_path)
        public_url = public_url_response
        
        print(f"âœ… [Job {job_id}] Subido: {public_url[:80]}...")
        
        return public_url
        
    except Exception as e:
        print(f"âŒ [Job {job_id}] Error subiendo: {e}")
        raise

def process_job(job):
    """Procesar un job completo"""
    
    job_id = job['id']
    user_id = job['user_id']
    
    start_time = time.time()
    
    try:
        print(f"\n{'='*60}")
        print(f"ğŸ‘• [Job {job_id}] Iniciando procesamiento")
        print(f"   User: {user_id}")
        print(f"   Type: {job.get('job_type', 'unknown')}")
        print(f"{'='*60}\n")
        
        # Actualizar estado a processing
        supabase.table('ai_generation_jobs').update({
            'status': 'processing',
            'started_at': datetime.utcnow().isoformat(),
            'progress': 10,
            'result_metadata': {
                'worker_id': WORKER_ID,
                'backend': 'vast',
                'started_at': datetime.utcnow().isoformat()
            }
        }).eq('id', job_id).execute()
        
        # Ejecutar ComfyUI workflow
        result_path = execute_comfy_workflow(job)
        
        # Actualizar progreso
        supabase.table('ai_generation_jobs').update({
            'progress': 90
        }).eq('id', job_id).execute()
        
        # Subir resultado a Storage
        public_url = upload_result_to_supabase(job_id, user_id, result_path)
        
        # Guardar en tryon_results
        supabase.table('tryon_results').insert({
            'user_id': user_id,
            'job_id': job_id,
            'result_url': public_url,
            'products_used': job['input_data'].get('products_metadata', [])
        }).execute()
        
        # Marcar job como completado
        processing_time = time.time() - start_time
        
        supabase.table('ai_generation_jobs').update({
            'status': 'completed',
            'progress': 100,
            'result_url': public_url,
            'completed_at': datetime.utcnow().isoformat(),
            'processing_time_seconds': round(processing_time, 2),
            'cost_usd': 0.005,  # Costo estimado en Vast
        }).eq('id', job_id).execute()
        
        # Notificar a Vast Manager que procesamos un job
        supabase.table('vast_instances').update({
            'last_job_at': datetime.utcnow().isoformat(),
            'jobs_processed': supabase.rpc('increment', {'x': 1}),
            'status': 'ready',  # Volver a ready despuÃ©s de procesar
        }).eq('worker_id', WORKER_ID).execute()
        
        print(f"âœ… [Job {job_id}] Completado en {processing_time:.1f}s")
        
        # Limpiar archivos temporales
        try:
            os.remove(result_path)
        except:
            pass
        
        return True
        
    except Exception as e:
        print(f"âŒ [Job {job_id}] Error: {e}")
        
        # Marcar job como fallido
        supabase.table('ai_generation_jobs').update({
            'status': 'failed',
            'error_message': str(e),
            'completed_at': datetime.utcnow().isoformat(),
        }).eq('id', job_id).execute()
        
        # Incrementar contador de fallos
        supabase.table('vast_instances').update({
            'jobs_failed': supabase.rpc('increment', {'x': 1}),
        }).eq('worker_id', WORKER_ID).execute()
        
        return False

def send_heartbeat():
    """Enviar heartbeat a Supabase"""
    try:
        supabase.table('vast_instances').update({
            'last_health_check': datetime.utcnow().isoformat(),
            'health_status': 'healthy',
        }).eq('worker_id', WORKER_ID).execute()
    except Exception as e:
        print(f"âš ï¸ Error enviando heartbeat: {e}")

def mark_instance_ready():
    """Marcar instancia como ready en BD"""
    try:
        supabase.table('vast_instances').update({
            'status': 'ready',
            'ready_at': datetime.utcnow().isoformat(),
            'health_status': 'healthy',
        }).eq('worker_id', WORKER_ID).execute()
        
        print(f"âœ… Instancia marcada como READY en Supabase")
    except Exception as e:
        print(f"âŒ Error marcando ready: {e}")

def main_loop():
    """Loop principal del worker"""
    
    print("â³ Esperando ComfyUI...")
    
    # Esperar a que ComfyUI estÃ© listo
    max_wait = 120  # 2 minutos
    waited = 0
    
    while not check_comfy_ready() and waited < max_wait:
        time.sleep(5)
        waited += 5
        if waited % 20 == 0:
            print(f"   Esperando... ({waited}s / {max_wait}s)")
    
    if not check_comfy_ready():
        print("âŒ ComfyUI no respondiÃ³ en 2 minutos - abortando")
        sys.exit(1)
    
    print("âœ… ComfyUI READY")
    
    # Marcar instancia como ready
    mark_instance_ready()
    
    # Contadores
    last_heartbeat = time.time()
    jobs_processed_total = 0
    
    print(f"\nğŸ¤– Worker {WORKER_ID} activo y esperando jobs...\n")
    
    # Loop infinito
    while True:
        try:
            # Heartbeat periÃ³dico
            if time.time() - last_heartbeat > WORKER_CONFIG['HEARTBEAT_INTERVAL_SECONDS']:
                send_heartbeat()
                last_heartbeat = time.time()
            
            # Buscar jobs pendientes para 'vast'
            response = supabase.table('ai_generation_jobs') \
                .select('*') \
                .eq('status', 'pending') \
                .eq('preferred_backend', 'vast') \
                .order('priority', desc=True) \
                .order('created_at') \
                .limit(WORKER_CONFIG['MAX_BATCH_SIZE']) \
                .execute()
            
            jobs = response.data
            
            if not jobs or len(jobs) == 0:
                # No hay jobs - marcar como idle
                supabase.table('vast_instances').update({
                    'status': 'idle',
                    'current_batch_size': 0,
                }).eq('worker_id', WORKER_ID).execute()
                
                if jobs_processed_total % 10 == 0 and jobs_processed_total > 0:
                    print(f"ğŸ’¤ Sin jobs ({jobs_processed_total} procesados total)")
                
                time.sleep(WORKER_CONFIG['POLL_INTERVAL_SECONDS'])
                continue
            
            batch_size = len(jobs)
            print(f"\nğŸš€ Procesando batch de {batch_size} job(s)")
            
            # Marcar como busy
            supabase.table('vast_instances').update({
                'status': 'busy',
                'current_batch_size': batch_size,
            }).eq('worker_id', WORKER_ID).execute()
            
            # Procesar batch (FCFS - uno a la vez por ahora)
            # TODO: Procesar en paralelo si VRAM lo permite
            for job in jobs:
                success = process_job(job)
                if success:
                    jobs_processed_total += 1
            
            print(f"âœ… Batch completado ({jobs_processed_total} total)\n")
            
        except KeyboardInterrupt:
            print("\n\nğŸ›‘ Worker detenido por usuario")
            break
            
        except Exception as e:
            print(f"âŒ Error en main loop: {e}")
            time.sleep(10)  # Esperar mÃ¡s en caso de error
    
    print(f"\nğŸ“Š EstadÃ­sticas finales:")
    print(f"   Jobs procesados: {jobs_processed_total}")
    print(f"   Worker ID: {WORKER_ID}")
    print("\nğŸ‘‹ Worker finalizado")

if __name__ == "__main__":
    try:
        main_loop()
    except Exception as e:
        print(f"âŒ Error fatal: {e}")
        sys.exit(1)
